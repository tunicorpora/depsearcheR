<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>DepsearcheR - querying syntactically annotated data with R</title>
  <meta name="description" content="DepsearcheR - querying syntactically annotated data with R">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="DepsearcheR - querying syntactically annotated data with R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="DepsearcheR - querying syntactically annotated data with R" />
  
  
  

<meta name="author" content="Juho Härme">


<meta name="date" content="2018-12-01">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#example-data"><i class="fa fa-check"></i><b>1</b> Example data</a></li>
<li class="chapter" data-level="2" data-path=""><a href="#usage-on-the-sentence-level"><i class="fa fa-check"></i><b>2</b> Usage on the sentence level</a></li>
<li class="chapter" data-level="3" data-path=""><a href="#usage-on-the-dataset-level"><i class="fa fa-check"></i><b>3</b> Usage on the dataset level</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#querying-a-raw-text"><i class="fa fa-check"></i><b>3.1</b> Querying a raw text</a><ul>
<li class="chapter" data-level="3.1.1" data-path=""><a href="#getting-parameters-from-the-results"><i class="fa fa-check"></i><b>3.1.1</b> Getting parameters from the results</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#filtering-concordances"><i class="fa fa-check"></i><b>3.2</b> Filtering concordances</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DepsearcheR - querying syntactically annotated data with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">DepsearcheR - querying syntactically annotated data with R</h1>
<h4 class="author"><em>Juho Härme</em></h4>
<h4 class="date"><em>2018-12-01</em></h4>
</div>
<p>The DepsearcheR package is a simple utility made for the purpose of using R for corpus analyses involving the utilization of dependency annotations represented in some version of the CoNLL format (cf. e.g <a href="https://stackoverflow.com/questions/27416164/what-is-conll-data-format">here</a>).</p>
<div id="example-data" class="section level1">
<h1><span class="header-section-number">1</span> Example data</h1>
<p>Assume that you have parsed a file like the one provided in the <code>inst/extdata</code> folder of this package (the Finnish wikipedia article for sparrow):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(depsearcheR)
<span class="kw">library</span>(readr)
mytext &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_file</span>(
                           <span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, 
                                       <span class="st">&quot;varpunen_wikipedia.txt&quot;</span>,
                                       <span class="dt">package=</span><span class="st">&quot;depsearcheR&quot;</span>)
                           )

<span class="kw">cat</span>(<span class="kw">substr</span>(mytext,<span class="dv">1</span>,<span class="dv">300</span>))</code></pre></div>
<pre><code>## Varpunen (Passer domesticus) on yleinen lintulaji suuressa osassa Eurooppaa ja Aasiaa. Carolus Linnaeus antoi varpuselle aluksi nimen Fringilla domestica.
## Varpunen on 14–17 cm pitkä ja painaa 30–33 g. Koiras on hieman kookkaampi. Varpusella on tukeva ruumis, suhteellisen suuri pää ja voimakas nokka.</code></pre>
<p>The text has been parsed with <a href="http://turkunlp.github.io/Finnish-dep-parser/">the Finnish dependency parser developed at the university of Turku</a> and this output file is also included in <code>inst/extdata</code>. Note that the format here is the so called universal dependencies format. This is what the conll formatted file looks like:</p>
<pre><code>1   Varpunen    varpunen    NOUN    _   Case=Nom|Number=Sing    8   nsubj:cop   _   _
2   (   (   PUNCT   _   _   4   punct   _   _
3   Passer  Passer  PROPN   _   Case=Nom|Number=Sing    4   compound:nn _   _
4   domesticus  domesticus  NOUN    _   Case=Nom|Number=Sing    1   appos   _   _
5   )   )   PUNCT   _   _   4   punct   _   _
6   on  olla    VERB    _   Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act 8   cop _   _
7   yleinen yleinen ADJ _   Case=Nom|Degree=Pos|Number=Sing 8   amod    _   _
8   lintulaji   lintu#laji  NOUN    _   Case=Nom|Number=Sing    0   root    _   _
9   suuressa    suuri   ADJ _   Case=Ine|Degree=Pos|Number=Sing 10  amod    _   _
10  osassa  osa NOUN    _   Case=Ine|Number=Sing    8   nmod    _   _
11  Eurooppaa   Eurooppa    PROPN   _   Case=Par|Number=Sing    10  nmod    _   _
12  ja  ja  CONJ    _   _   11  cc  _   _
13  Aasiaa  Aasia   PROPN   _   Case=Par|Number=Sing    11  conj    _   _
14  .   .   PUNCT   _   _   8   punct   _   _

1   Carolus Carolus PROPN   _   Case=Nom|Number=Sing    2   name    _   _
2   Linnaeus    Linnaeus    PROPN   _   Case=Nom|Number=Sing    3   nsubj   _   _
3   antoi   antaa   VERB    _   Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin|Voice=Act 0   root    _   _
4   varpuselle  varpunen    NOUN    _   Case=All|Number=Sing    3   nmod    _   _
5   aluksi  aluksi  ADV _   _   3   advmod  _   _
6   nimen   nimi    NOUN    _   Case=Gen|Number=Sing    7   nmod:poss   _   _
7   Fringilla   Fringilla   NOUN    _   Case=Ade|Number=Plur    3   nmod    _   _
8   domestica   domestica   X   _   Foreign=Foreign 3   dobj    _   _
9   .   .   PUNCT   _   _   3   punct   _   _</code></pre>
<p>Now, let’s imagine we have a data set consisting of all the sentences of the Finnish wikipedia article mentioned above. It could be acquired as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(readr)
sentences &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_file</span>(
                           <span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, 
                                       <span class="st">&quot;varpunen.conll&quot;</span>,
                                       <span class="dt">package=</span><span class="st">&quot;depsearcheR&quot;</span>)
                           ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">strsplit</span>(<span class="st">&quot;</span><span class="ch">\n\n</span><span class="st">&quot;</span>)  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>unlist</code></pre></div>
<p>The data is also included in the package as a sample vector called <code>varpunen_sentences</code>, which we will use in the following examples.</p>
<p>Now, since there is some variation among the different conll formats and not all conll outputs have the same number of columns, you should set the columns used in each session as a global option via the <code>options</code> function. For instance, for the results of the Stanford parser’s 2015 version, we should do:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="st">&quot;conll_cols&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;tokenid&quot;</span>,<span class="st">&quot;token&quot;</span>,<span class="st">&quot;lemma&quot;</span>,<span class="st">&quot;feat&quot;</span>,<span class="st">&quot;none&quot;</span>, <span class="st">&quot;head&quot;</span>, <span class="st">&quot;dep&quot;</span>))</code></pre></div>
<p>Since in the following examples we’ll be using the Finnish dep parser, we’ll set it like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="st">&quot;conll_cols&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;tokenid&quot;</span>,<span class="st">&quot;token&quot;</span>,<span class="st">&quot;lemma&quot;</span>,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;pos2&quot;</span>,<span class="st">&quot;feat&quot;</span>,<span class="st">&quot;head&quot;</span>,<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;null1&quot;</span>,<span class="st">&quot;null2&quot;</span>))</code></pre></div>
</div>
<div id="usage-on-the-sentence-level" class="section level1">
<h1><span class="header-section-number">2</span> Usage on the sentence level</h1>
<p>At the heart of the depsearcheR package is an extremely simple function called <code>FilterConllRows</code>. The idea of this function is to filter a conll formatted sentence according to some conditions given by the users. The output of the filter can then be used for more filtering.</p>
<p>As simple and trivial scenario, imagine that we want to retrieve all the nouns of a sentence. This could be achieved in the following way (using the example set of sentences from the previous section):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">1</span>], <span class="st">&quot;pos&quot;</span>, <span class="st">&quot;NOUN&quot;</span>)</code></pre></div>
<pre><code>## # A tibble: 4 x 10
##   tokenid token      lemma      pos   pos2  feat    head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       1 Varpunen   varpunen   NOUN  _     Case=…     8 nsub… _     _    
## 2       4 domesticus domesticus NOUN  _     Case=…     1 appos _     _    
## 3       8 lintulaji  lintu#laji NOUN  _     Case=…     0 root  _     _    
## 4      10 osassa     osa        NOUN  _     Case=…     8 nmod  _     _</code></pre>
<p>The function can also be used with regular expressions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">1</span>], <span class="st">&quot;feat&quot;</span>, <span class="st">&quot;Case=Ine&quot;</span>, <span class="dt">use_regex=</span>T)</code></pre></div>
<pre><code>## # A tibble: 2 x 10
##   tokenid token    lemma pos   pos2  feat           head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       9 suuressa suuri ADJ   _     Case=Ine|Deg…    10 amod  _     _    
## 2      10 osassa   osa   NOUN  _     Case=Ine|Num…     8 nmod  _     _</code></pre>
<p>…conditions with multiple values</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">1</span>], <span class="st">&quot;pos&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;NOUN&quot;</span>,<span class="st">&quot;ADJ&quot;</span>))</code></pre></div>
<pre><code>## # A tibble: 6 x 10
##   tokenid token      lemma      pos   pos2  feat    head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       1 Varpunen   varpunen   NOUN  _     Case=…     8 nsub… _     _    
## 2       4 domesticus domesticus NOUN  _     Case=…     1 appos _     _    
## 3       7 yleinen    yleinen    ADJ   _     Case=…     8 amod  _     _    
## 4       8 lintulaji  lintu#laji NOUN  _     Case=…     0 root  _     _    
## 5       9 suuressa   suuri      ADJ   _     Case=…    10 amod  _     _    
## 6      10 osassa     osa        NOUN  _     Case=…     8 nmod  _     _</code></pre>
<p>or with negative conditions, for instance to get everything that’s not a noun or an adjective (or a punctuation mark):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">1</span>], <span class="st">&quot;pos&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;NOUN&quot;</span>,<span class="st">&quot;ADJ&quot;</span>,<span class="st">&quot;PROPN&quot;</span>,<span class="st">&quot;PUNCT&quot;</span>), <span class="dt">is_negative=</span>T)</code></pre></div>
<pre><code>## # A tibble: 2 x 10
##   tokenid token lemma pos   pos2  feat              head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;            &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       6 on    olla  VERB  _     Mood=Ind|Number…     8 cop   _     _    
## 2      12 ja    ja    CONJ  _     _                   11 cc    _     _</code></pre>
<p>You can add more complex conditions by piping the reslts in <code>dplyr</code> style. Note that since the philosophy behind this package relies quite heavily on the one behind dplyr (or the <code>tidyverse</code> framework in general) it might be a good idea to get a basic idea of what that is about (e.g. <a href="https://dplyr.tidyverse.org/articles/dplyr.html#piping">here</a>). The very basic thing to note: the <code>%&gt;%</code> operator used in the following examples is called the piping operator (from the <code>magrittr</code> package) and it’s a way to pass on a functions return value to another function.</p>
<p>So, to get, for instance, something that is not a noun but is in the inessive case, we might do:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">1</span>], <span class="st">&quot;pos&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;NOUN&quot;</span>,<span class="st">&quot;PROPN&quot;</span>),<span class="dt">is_negative=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;Case=Ine&quot;</span>, <span class="dt">use_regex=</span>T) </code></pre></div>
<pre><code>## # A tibble: 1 x 10
##   tokenid token    lemma pos   pos2  feat           head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       9 suuressa suuri ADJ   _     Case=Ine|Deg…    10 amod  _     _</code></pre>
<p>And actually, with the piping style going on, we could start with the sentence:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varpunen_sentences[<span class="dv">1</span>]  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;pos&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;NOUN&quot;</span>,<span class="st">&quot;PROPN&quot;</span>),<span class="dt">is_negative=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;Case=Ine&quot;</span>, <span class="dt">use_regex=</span>T) </code></pre></div>
<pre><code>## # A tibble: 1 x 10
##   tokenid token    lemma pos   pos2  feat           head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       9 suuressa suuri ADJ   _     Case=Ine|Deg…    10 amod  _     _</code></pre>
<p>Stylistically, this looks a little better to me.</p>
<p>This kind of “filtering the filtered” is where the function actually gets useful for getting information about dependencies.</p>
<p>Now, imagine we want to get all the dependents of a finite verb in a sentence. For that, we can use the values of the columns <code>head</code> and <code>tokenid</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Get all the finite verbs in the sentence</span>
finverbs &lt;-<span class="st"> </span><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">2</span>], <span class="st">&quot;feat&quot;</span>, <span class="st">&quot;VerbForm=Fin&quot;</span>, T)
<span class="co">#Get their dependents</span>
deps &lt;-<span class="st"> </span><span class="kw">FilterConllRows</span>(varpunen_sentences[<span class="dv">2</span>], <span class="st">&quot;head&quot;</span>, finverbs<span class="op">$</span>tokenid)
deps</code></pre></div>
<pre><code>## # A tibble: 6 x 10
##   tokenid token      lemma     pos   pos2  feat     head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       2 Linnaeus   Linnaeus  PROPN _     Case=N…     3 nsubj _     _    
## 2       4 varpuselle varpunen  NOUN  _     Case=A…     3 nmod  _     _    
## 3       5 aluksi     aluksi    ADV   _     _           3 advm… _     _    
## 4       7 Fringilla  Fringilla NOUN  _     Case=A…     3 nmod  _     _    
## 5       8 domestica  domestica X     _     Foreig…     3 dobj  _     _    
## 6       9 .          .         PUNCT _     _           3 punct _     _</code></pre>
<p>There is actually a shortcut function for getting the dependents of a word. It’s called <code>GetDeps</code> and it takes as it’s arguments</p>
<ul>
<li>a word (=a row of a tibble) or multiple words (a tibble) that are the heads we’re looking at</li>
<li>an unfiltered sentence (as a tibble)</li>
</ul>
<p>So, the previous example could be written as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varpunen_sentences[<span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;VerbForm=Fin&quot;</span>, T) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># returns one row, passed on to the GetDeps function</span>
<span class="st">    </span><span class="kw">GetDeps</span>(varpunen_sentences[<span class="dv">2</span>])  <span class="co"># note: the original sentence is the second argument</span></code></pre></div>
<pre><code>## # A tibble: 6 x 10
##   tokenid token      lemma     pos   pos2  feat     head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       2 Linnaeus   Linnaeus  PROPN _     Case=N…     3 nsubj _     _    
## 2       4 varpuselle varpunen  NOUN  _     Case=A…     3 nmod  _     _    
## 3       5 aluksi     aluksi    ADV   _     _           3 advm… _     _    
## 4       7 Fringilla  Fringilla NOUN  _     Case=A…     3 nmod  _     _    
## 5       8 domestica  domestica X     _     Foreig…     3 dobj  _     _    
## 6       9 .          .         PUNCT _     _           3 punct _     _</code></pre>
<p>There is also the <code>GetHeads</code> function for doing this the other way around: if we want to, say, find all the heads of (common) nouns, we could do it as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varpunen_sentences[<span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;pos&quot;</span>, <span class="st">&quot;NOUN&quot;</span>) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">    </span><span class="kw">GetHeads</span>(varpunen_sentences[<span class="dv">2</span>])  </code></pre></div>
<pre><code>## # A tibble: 2 x 10
##   tokenid token     lemma     pos   pos2  feat      head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       3 antoi     antaa     VERB  _     Mood=In…     0 root  _     _    
## 2       7 Fringilla Fringilla NOUN  _     Case=Ad…     3 nmod  _     _</code></pre>
<p>Note that we can use the output of <code>GetDeps</code> and <code>GetHeads</code> for further filtering, for instance to get only the kind of dependents for finite verbs that are <em>not</em> nouns (or punctuation marks):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varpunen_sentences[<span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;VerbForm=Fin&quot;</span>, T) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">    </span><span class="kw">GetDeps</span>(varpunen_sentences[<span class="dv">2</span>])   <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;pos&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;PROPN&quot;</span>, <span class="st">&quot;NOUN&quot;</span>, <span class="st">&quot;PUNCT&quot;</span>), <span class="dt">is_negative=</span>T)</code></pre></div>
<pre><code>## # A tibble: 2 x 10
##   tokenid token     lemma     pos   pos2  feat      head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       5 aluksi    aluksi    ADV   _     _            3 advm… _     _    
## 2       8 domestica domestica X     _     Foreign…     3 dobj  _     _</code></pre>
</div>
<div id="usage-on-the-dataset-level" class="section level1">
<h1><span class="header-section-number">3</span> Usage on the dataset level</h1>
<p>All the previous examples demonstrate the usage of the simple functions in this package on the sentence level. What the whole package is actually for, is, however, querying datastructures containing multiple sentences and filtering only the ones that are relevant for the user.</p>
<p>It should be emphasized at this point that this package is definitely not meant for effective data mining on a large scale. The functions used are simple, perhaps even trivial, and performance is the cost. But if you know what you’re searching for and are not dealing with a terribly large dataset (or have a lot of time) this can be a useful approach.</p>
<div id="querying-a-raw-text" class="section level2">
<h2><span class="header-section-number">3.1</span> Querying a raw text</h2>
<p>The first, although propably not the most common, use case considered here is where you have a conll formatted text (such as the one from the first section of this vignette) and you want to make queries to find sentences with certain characteristics. To do that, we want to have the data formatted as a vector of sentences.</p>
<p>Since the data in conll format separates sentences with an empty row, a vector of sentences can be obtained simply by splitting the file by two consequtive newlines as was done at the beginning of this vignette. There is also a convenience function for this, which takes a filename as a parameter and produces the vector:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentences  &lt;-<span class="st"> </span><span class="kw">GetSentencesFromFile</span>(<span class="st">&quot;inst/extdata/varpunen.conll&quot;</span>)</code></pre></div>
<p>Now, let’s say we want to get all the sentences</p>
<ol style="list-style-type: decimal">
<li>which include a finite verb</li>
<li>in which the finite verb has a subject dependent</li>
<li>in which the subject is a proper name</li>
</ol>
<!-- -->
<p>The trick here is to develop custom functions that will take care of the filtering and then apply those functions to the vector containing the sentences. Here’s an example function that can be used for searching for only the kind of results described above (has a finite verb, the verb has a subject dependent, the subject is a proper name)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MyFilterFunction &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>,<span class="st">&quot;VerbForm=Fin&quot;</span>, T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;PROPN&quot;</span>)  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
} </code></pre></div>
<p>There is one requirement to keep in mind when creating these filters: every filter must take a single sentence as its only argument and return the filtered matches so that they can be further processed. Before the return statement you can have as complex or as simple a set of code as you wish. The filters should be used with the <code>ApplyConllFilter</code> function of this library in the following manner:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="st">&quot;conll_cols&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;tokenid&quot;</span>,<span class="st">&quot;token&quot;</span>,<span class="st">&quot;lemma&quot;</span>,<span class="st">&quot;pos&quot;</span>,<span class="st">&quot;pos2&quot;</span>,<span class="st">&quot;feat&quot;</span>,<span class="st">&quot;head&quot;</span>,<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;null1&quot;</span>,<span class="st">&quot;null2&quot;</span>))
matched_sentences &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(varpunen_sentences, MyFilterFunction)</code></pre></div>
<p>By default <code>ApplyConllFilter</code> just returns the sentences of the input vector that matched the specified filter. In our case, there was one sentence that matched the query. To view the sentence as a tibble, we can use the function <code>ConllAsTibble</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ConllAsTibble</span>(matched_sentences)</code></pre></div>
<pre><code>## # A tibble: 9 x 10
##   tokenid token      lemma     pos   pos2  feat     head dep   null1 null2
##     &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;
## 1       1 Carolus    Carolus   PROPN _     Case=N…     2 name  _     _    
## 2       2 Linnaeus   Linnaeus  PROPN _     Case=N…     3 nsubj _     _    
## 3       3 antoi      antaa     VERB  _     Mood=I…     0 root  _     _    
## 4       4 varpuselle varpunen  NOUN  _     Case=A…     3 nmod  _     _    
## 5       5 aluksi     aluksi    ADV   _     _           3 advm… _     _    
## 6       6 nimen      nimi      NOUN  _     Case=G…     7 nmod… _     _    
## 7       7 Fringilla  Fringilla NOUN  _     Case=A…     3 nmod  _     _    
## 8       8 domestica  domestica X     _     Foreig…     3 dobj  _     _    
## 9       9 .          .         PUNCT _     _           3 punct _     _</code></pre>
<p>Or, if we would like a more human-readable representation of the actual sentence, there is a function called <code>ConllAsSentence</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ConllAsSentence</span>(matched_sentences)</code></pre></div>
<pre><code>## [1] &quot;Carolus Linnaeus antoi varpuselle aluksi nimen Fringilla domestica.&quot;</code></pre>
<p>Keep in mind, however, that these two functions take <em>single</em> sentences as arguments, not vectors of sentences.</p>
<p>If we want different kind of output from <code>ApplyConllFilter</code>, we can specify this via the <code>return_type</code> parameter. This parameter is a string defaulting to “raw” (the kind of output we got above, i.e. just a filtered vector of conll-formatted sentences). Other possible values are:</p>
<ul>
<li><code>matches</code>: returns all the words (rows) that match as a single tibble.</li>
<li><code>both</code>: returns both the matching words and the conll output as an additional column (<code>sent</code>)</li>
<li><code>both_pretty</code>: same as above but instead of the raw conll string converts the sentence to a human readable format</li>
</ul>
<p>The <code>matches</code> version of the output is useful if we want to further analyze the results of our queries, not just count how many matches we got. This will be more closely illustrated below.</p>
<p>The kind of queries presented above work okay with the kind of toy files used here as examples. However, if we have a larger text, this really not an effective way of mining it. However, if you don’t mind the query running for a while, you can, of course, give this approach a go. For that kind cases, <code>ApplyConllFilter</code> uses a progress bar with an estimation of the remaining time (the proggress bar itself is part of the <code>dplyr</code> package).</p>
<p>As a larger example, consider querying the entire (English translation of the) gospel of John<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> with a similar filter. This set of sentences is included with the package as a vector called <code>gospel_of_john_sentences</code>. Note that since we are now switching to a different kind of parser output, we must define the expected columns again using the <code>options</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AnotherFilter &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, <span class="dt">use_regex=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;VV&quot;</span>, <span class="dt">is_negative=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;NN&quot;</span>,<span class="st">&quot;NNP&quot;</span>))  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}

<span class="kw">options</span>(<span class="st">&quot;conll_cols&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;tokenid&quot;</span>,<span class="st">&quot;token&quot;</span>,<span class="st">&quot;lemma&quot;</span>,<span class="st">&quot;feat&quot;</span>,<span class="st">&quot;none&quot;</span>, <span class="st">&quot;head&quot;</span>, <span class="st">&quot;dep&quot;</span>))
start.time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()
matched_sentences &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(gospel_of_john_sentences, AnotherFilter)
<span class="kw">show</span>(<span class="kw">Sys.time</span>() <span class="op">-</span><span class="st"> </span>start.time)</code></pre></div>
<pre><code>## Time difference of 3.992389 secs</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">show</span>(<span class="kw">length</span>(matched_sentences))</code></pre></div>
<pre><code>## [1] 501</code></pre>
<!-- TODO: a function called GetColFromConll etc -->
<p>As you can see, on my thinkpad x220 that took around 3 seconds – still not terribly bad. To get the perspective: this version of the gospel of John has 1,218 sentences. Of these, our search criteria were met by 501.</p>
<p>As a somewhat more serious work load, let’s try to parse the whole New testament. That means 9,329 sentences (not included in this package).</p>
<p>The result (on the same icore5 2.5ghz processor): <code>Time difference of 16.20708 secs</code></p>
<p>So, let’s say that 17 seconds for around 10,000 sentences. If it means that 100,000 sentences will be analyzed in 170 seconds = a little less than 3 minutes, well – you get the perspective. Not the most effective way, but suitable for many cases, and if you’ve got time to wait, even for some more serious text mining assignments.</p>
<div id="getting-parameters-from-the-results" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Getting parameters from the results</h3>
<p>In the previous examples we retrieved sentences by different filters and so far we have relied on the raw output of <code>ApplyConllFilter.</code> Let’s move on to imagining a scenario in which we want to get specific parameters out of the filtered results, that is, to specifying <code>return_type = 'matches'</code>..</p>
<p>Consider the previous example with the sentences from the Gospel of John. Our little filter, repeated below, obtained all the cases where a finite verb had a subject dependent which was a noun:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AnotherFilter &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, <span class="dt">use_regex=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;NN&quot;</span>,<span class="st">&quot;NNP&quot;</span>))  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}


matched_words &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(gospel_of_john_sentences, AnotherFilter, <span class="st">&quot;matches&quot;</span>)</code></pre></div>
<p>Now we have a tibble called <code>matched_words</code> which contains all the words (all the rows from the conll representations of sentences). With this tibble we can do any statistical operations we would normally do with or data sets. As an especially simple example, think about taking all the subject dependents of finite verbs in the gospel of John and looking at which lemmas are most frequent as the subject:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matched_words <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(lemma)  <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<pre><code>## # A tibble: 129 x 2
##    lemma         n
##    &lt;fct&gt;     &lt;int&gt;
##  1 Jesus       187
##  2 Father       29
##  3 man          23
##  4 Peter        19
##  5 one          18
##  6 world        15
##  7 Pilate       14
##  8 Lord         11
##  9 multitude    11
## 10 John         10
## # ... with 119 more rows</code></pre>
<p>No surprise, the most frequent subject is the proper name “Jesus”. But what is it that he keeps on doing? Let’s modify the filter a little:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">YetAnotherFilter &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, <span class="dt">use_regex=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;lemma&quot;</span>, <span class="st">&quot;Jesus&quot;</span>)  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetHeads</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}

verbs_with_Jesus &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(gospel_of_john_sentences,YetAnotherFilter,<span class="st">&quot;both_pretty&quot;</span>)</code></pre></div>
<p>The filter became a little circular (we’re first taking all the dependents of verbs, then filtering those and then getting their heads again…), but it does the job:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">verbs_with_Jesus <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(lemma) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<pre><code>## # A tibble: 35 x 2
##    lemma      n
##    &lt;fct&gt;  &lt;int&gt;
##  1 say       65
##  2 answer    36
##  3 come      16
##  4 do         9
##  5 go         7
##  6 speak      6
##  7 love       6
##  8 see        5
##  9 walk       4
## 10 make       3
## # ... with 25 more rows</code></pre>
<p>Now, what if we would like to combine this information to get ngrams of sorts?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, <span class="dt">use_regex=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;NN&quot;</span>,<span class="st">&quot;NNP&quot;</span>))  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}


b &lt;-<span class="st"> </span><span class="cf">function</span>(sentence) {
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, <span class="dt">use_regex=</span>T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetDeps</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>,<span class="st">&quot;nsubj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;NN&quot;</span>,<span class="st">&quot;NNP&quot;</span>))  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetHeads</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}


subj &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(gospel_of_john_sentences,a,<span class="st">&quot;both_pretty&quot;</span>)
verb &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(gospel_of_john_sentences,b,<span class="st">&quot;both_pretty&quot;</span>)

tab &lt;-<span class="st"> </span>subj <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(lemma, sent) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">left_join</span>(verb  <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(lemma, sent), <span class="dt">by=</span><span class="st">&quot;sent&quot;</span>)   <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">count</span>(lemma.x, lemma.y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">arrange</span>(lemma.x, <span class="kw">desc</span>(n)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">filter</span>(n<span class="op">&gt;</span><span class="dv">4</span>) 

tab  <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n=</span><span class="dv">99</span>)</code></pre></div>
<pre><code>## # A tibble: 18 x 3
##    lemma.x lemma.y     n
##    &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;
##  1 Jesus   say        65
##  2 Jesus   answer     36
##  3 Jesus   come       24
##  4 Jesus   do         11
##  5 Jesus   go          8
##  6 Jesus   love        7
##  7 Jesus   be          6
##  8 Jesus   speak       6
##  9 Jesus   see         6
## 10 Jesus   know        5
## 11 Father  give        6
## 12 one     come        7
## 13 hour    come        6
## 14 time    come        8
## 15 Christ  come        5
## 16 Peter   say         5
## 17 woman   say         5
## 18 Pilate  say         6</code></pre>
<p>And we could, of course keep on going and draw some graphs, build statistical models and so on… A correspondence analysis, maybe?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ca)

subj <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(lemma, sent) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">left_join</span>(verb  <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(lemma, sent), <span class="dt">by=</span><span class="st">&quot;sent&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">filter</span>(lemma.x <span class="op">%in%</span><span class="st"> </span>tab<span class="op">$</span>lemma.x, lemma.y <span class="op">%in%</span><span class="st"> </span>tab<span class="op">$</span>lemma.y)  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">lemma.x =</span> <span class="kw">as.character</span>(lemma.x), <span class="dt">lemma.y=</span><span class="kw">as.character</span>(lemma.y)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ca</span>(<span class="op">~</span>lemma.x <span class="op">+</span><span class="st"> </span>lemma.y, <span class="dt">data=</span>.) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>plot</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
</div>
<div id="filtering-concordances" class="section level2">
<h2><span class="header-section-number">3.2</span> Filtering concordances</h2>
<p>Although it is certainly possible to use this library for querying entire texts outputted in the conll format, the use case for which the library was created is when you have a data frame containing a list of concordances with more information than just the actual conll-annotated sentence.</p>
<p>The basic idea is to have the data in a data frame / tibble where one row corresponds to one sentence (or one relevant annotated context of any length) and there is a column containing the conll representation of the sentence. In addition, you probably have some variables, at least metadata an the like. One sample use case is, for instance, if you’ve queried for Twitter data and would like to have each tweet parsed and then use the conll output of the tweet together with the massive amounts of metadata variables provided by the Twitter API for each tweet.</p>
<p>Here’s a toy example of such a task.</p>
<p>Let’s imagine we want to analyze the usage of the word “referee” in recent Uefa champions’ league games (recent, because the Twitter api only let’s you search for tweets not older than one week). In order to run the following you need to have requested developer access from Twitter, but never mind, the data is also available as a small data set accompanying this package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#library(rtweet)</span>
<span class="co">#ref &lt;- search_tweets(&quot;(#UCL OR #ChampionsLeague OR #UEFAChampionsLeague) referee&quot;,  n = 5000)</span></code></pre></div>
<p>I used the method described in the context of the <a href="https://github.com/utacorpora/webcorpcrawler/blob/master/docs/add_annotations_example.md">webcorpcrawler python utility</a> to add syntactic annotations using Stanford Core-NLP. This gave me the following data set, available, as mentioned, as part of this package. (I’ve stripped away most of the props offered by the Twitter API since there is A LOT of them)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ucl_ref</code></pre></div>
<pre><code>## # A tibble: 262 x 6
##    text     followers retweets favorites location parsed_text             
##    &lt;chr&gt;        &lt;int&gt;    &lt;int&gt;     &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;                   
##  1 &quot;Here&#39;s…      8251        1         1 Berlin,… &quot;1\tHere\there\tRB\t_\t…
##  2 &quot;\&quot;We l…       146        1         0 Kraków,… &quot;1\t``\t``\t``\t_\t3\tp…
##  3 &quot;#Wedne…        58        7         0 lagos c… &quot;1\t#WednesdayWisdom\t#…
##  4 &quot;This r…     20546       28         0 South A… &quot;1\tThis\tthis\tDT\t_\t…
##  5 &quot;They m…      4310        0         0 Lagos N… &quot;1\tThey\tthey\tPRP\t_\…
##  6 &quot;This r…     11689       28         0 ☆S I Y … &quot;1\tThis\tthis\tDT\t_\t…
##  7 &quot;Jurgen…      4566        1         3 New Del… &quot;1\tJurgen\tJurgen\tNNP…
##  8 &quot;#Jurge…       506        0         0 Armenia  &quot;1\t#JurgenKlopp\t#jurg…
##  9 Liverpo…     34247        1         0 Paris, … &quot;1\tLiverpool\tLiverpoo…
## 10 Liverpo…     34247        1         0 Paris, … &quot;1\tLiverpool\tLiverpoo…
## # ... with 252 more rows</code></pre>
<p>In the <code>ucl_ref</code> dataset, the conll annotated raw text is stored in the <code>parsed_text</code> column. Let’s do something analogous to the previous example and look at the verbs the word ‘referee’ is an object of. First, let’s build our filter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_filt &lt;-<span class="st"> </span><span class="cf">function</span>(sentence){
    sentence  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;lemma&quot;</span>, <span class="st">&quot;referee&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;dep&quot;</span>, <span class="st">&quot;dobj&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">GetHeads</span>(sentence) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">FilterConllRows</span>(<span class="st">&quot;feat&quot;</span>, <span class="st">&quot;^V&quot;</span>, T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>return
}</code></pre></div>
<p>We could test the filter with using just the parsed_text column as a vector:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matches &lt;-<span class="st"> </span><span class="kw">ApplyConllFilter</span>(ucl_ref<span class="op">$</span>parsed_text, ref_filt)

<span class="kw">show</span>(<span class="kw">length</span>(matches))</code></pre></div>
<pre><code>## [1] 12</code></pre>
<p>Right, 12 matches, so the filter is working. But how to filter the actual data frame, not just the column with the annotated sentences? For this use case, the package includes a version of the <code>ApplyConllFilter</code> called <code>ApplyConllFilter_df</code>. Its first argument is the tibble (or data frame) to be filtered, the second argument is the custom filter function we’ve created and the third argument is the name of the column containing the conll annototated sentence. To filter our <code>ucl_ref</code> tibble so that we’re left with only the cases where the word <em>referee</em> is used as a direct object of a verb we would simply run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_as_obj &lt;-<span class="st"> </span>ucl_ref <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ApplyConllFilter_df</span>(ref_filt, <span class="st">&quot;parsed_text&quot;</span>) </code></pre></div>
<p>…and we get the twelve rows that match the condition. We could now check the metadata of the rows to look at, for instance, where these kinds of tweets are coming from:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_as_obj  <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">count</span>(location)</code></pre></div>
<pre><code>## # A tibble: 12 x 2
##    location                           n
##    &lt;chr&gt;                          &lt;int&gt;
##  1 &quot;&quot;                                 1
##  2 🏴󠁧󠁢󠁳󠁣󠁴󠁿                                 1
##  3 City Of Compton                    1
##  4 England, United Kingdom            1
##  5 Heathrow                           1
##  6 In My Liverpool Home               1
##  7 India                              1
##  8 İstanbul, Türkiye                  1
##  9 London | England                   1
## 10 Northern Ireland                   1
## 11 Royal Tunbridge Wells, England     1
## 12 Scotland                           1</code></pre>
<p>We can also spesify, if we want our data set filter to return an additional column (called <code>filtered_col</code>) which contains some property of the word (TODO: words) matched by the filter. For instance, if we would like to get the lemmas of the head verbs in the cases where <em>referee</em> is used as a direct object, we could do:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">filtered &lt;-<span class="st"> </span>ucl_ref <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ApplyConllFilter_df</span>(ref_filt, <span class="st">&quot;parsed_text&quot;</span>, <span class="dt">return_col=</span><span class="st">&quot;lemma&quot;</span>)   </code></pre></div>
<p>Now we could check, for instance, if a certain verb + <em>referee</em> as the object combination attracts more retweets than others by using the metadata available in the data frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">filtered <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">count</span>(filtered_col, retweets) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<pre><code>## # A tibble: 10 x 3
##    filtered_col retweets     n
##    &lt;fct&gt;           &lt;int&gt; &lt;int&gt;
##  1 get                 0     2
##  2 surround            0     2
##  3 criticise           0     1
##  4 play                0     1
##  5 berate              0     1
##  6 pay                 0     1
##  7 include             0     1
##  8 hope                0     1
##  9 go                  0     1
## 10 announce            0     1</code></pre>
<p>Well, oviously the data set here is too limited to get any kind of reasonable results, but you get the idea.</p>
<p>As a final remark about the <code>ApplyConllFilter_df</code> function, it should be added that there is also the possibility to return the whole data frame with the <code>filtered_col</code> column so that for the rows that don’t match the syntactic filter the function just returns NA:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">filtered2 &lt;-<span class="st"> </span>ucl_ref <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ApplyConllFilter_df</span>(ref_filt, <span class="st">&quot;parsed_text&quot;</span>, <span class="dt">return_col=</span><span class="st">&quot;lemma&quot;</span>, <span class="dt">return_all =</span> T) 


filtered2  <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(filtered_col) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<pre><code>## # A tibble: 11 x 2
##    filtered_col     n
##    &lt;chr&gt;        &lt;int&gt;
##  1 &lt;NA&gt;           250
##  2 get              2
##  3 surround         2
##  4 announce         1
##  5 berate           1
##  6 criticise        1
##  7 go               1
##  8 hope             1
##  9 include          1
## 10 pay              1
## 11 play             1</code></pre>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Included, also, as a sample file from the public domain World English version and parsed with the Stanford coreNLP parser.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

</body>

</html>
